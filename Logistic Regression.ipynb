{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Logistic Regression in Spark", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+---+---+---+------------+--------------------+\n|  x|  y|  z|       Class|              Source|\n+---+---+---+------------+--------------------+\n| 55| 13| 35|Climb_stairs|Accelerometer-201...|\n| 12| 35| 36|Climb_stairs|Accelerometer-201...|\n| 13| 34| 35|Climb_stairs|Accelerometer-201...|\n| 12| 36| 36|Climb_stairs|Accelerometer-201...|\n| 12| 36| 36|Climb_stairs|Accelerometer-201...|\n| 12| 36| 35|Climb_stairs|Accelerometer-201...|\n| 14| 36| 34|Climb_stairs|Accelerometer-201...|\n| 12| 36| 35|Climb_stairs|Accelerometer-201...|\n| 11| 36| 35|Climb_stairs|Accelerometer-201...|\n| 12| 35| 36|Climb_stairs|Accelerometer-201...|\n| 11| 34| 35|Climb_stairs|Accelerometer-201...|\n| 12| 35| 37|Climb_stairs|Accelerometer-201...|\n| 13| 35| 37|Climb_stairs|Accelerometer-201...|\n| 10| 35| 36|Climb_stairs|Accelerometer-201...|\n|  8| 35| 38|Climb_stairs|Accelerometer-201...|\n|  9| 37| 38|Climb_stairs|Accelerometer-201...|\n| 13| 35| 37|Climb_stairs|Accelerometer-201...|\n| 13| 36| 37|Climb_stairs|Accelerometer-201...|\n| 13| 35| 37|Climb_stairs|Accelerometer-201...|\n| 14| 36| 37|Climb_stairs|Accelerometer-201...|\n+---+---+---+------------+--------------------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "283385\n70890\n"
                }
            ], 
            "source": "# split the data frame into train and test sample\nsplits = df.randomSplit([0.8,0.2])\ndf_train = splits[0]\ndf_test = splits[1]\nprint(df_train.count())\nprint(df_test.count())"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# build the stages of pipeline\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Normalizer\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.classification import LogisticRegression\n\nindexer = StringIndexer(inputCol='Class',outputCol='label')\n#encoder = OneHotEncoder(inputCol='')\nvectorAssembler = VectorAssembler(inputCols = ['x','y','z'],outputCol = 'features')\nnormalizer = Normalizer(inputCol = 'features',outputCol='features_norm')\nlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# build the pipeline\nfrom pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer, lr])"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# fit the pipeline to train data\nmodel = pipeline.fit(df_train)\n\n# predict using transform\nprediction = model.transform(df_train)"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 15, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.12926583975863226"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# evaluate the performance of model (accuracy)\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nevaluator = MulticlassClassificationEvaluator().setMetricName('accuracy').setLabelCol('label').setPredictionCol('prediction')\n\nevaluator.evaluate(prediction)"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# evaluate on test dataframe\nmodel_test = pipeline.fit(df_test)"
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "prediction_test = model.transform(df_test)"
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 18, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.1293412328960361"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "evaluator.evaluate(prediction_test)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}